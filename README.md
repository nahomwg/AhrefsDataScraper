<pre><code># Ahrefs Backlink Checker Scraper ## üõ†Ô∏è Installation 1. Clone the repository and navigate to the project folder: ```bash git clone https://github.com/your-username/ahrefs-scraper.git cd ahrefs-scraper ``` 2. Install the required dependencies: ```bash npm install ``` > This project uses: > - `puppeteer-real-browser` > - `puppeteer-extra-plugin-stealth` --- ## ‚ñ∂Ô∏è Running the Script Make sure `input.json` is in the root directory and structured like this: ```json [ { "domain": "notion.so" }, { "domain": "webflow.com" }, { "domain": "linear.app" } ] ``` Then run: ```bash node scraper.js ``` The script will launch a real browser, scrape SEO metrics for each domain, and save them to `results.json`. --- ## üß† Approach & Design Decisions - **Automation Framework:** Used `puppeteer-real-browser` to simulate a real user browser with stealth capabilities. - **CAPTCHA Handling:** Instead of using a CAPTCHA-solving service, we used browser fingerprinting evasion (`puppeteer-extra-plugin-stealth`) and human-like interaction to trigger and solve Cloudflare Turnstile manually. - **Scraping Logic:** Metrics are extracted contextually by matching labels (e.g., "Backlinks", "Linking websites") to ensure accurate data collection from a modal-based interface. - **Modularity:** Code is split into modules (`/scraper`, `/utils`) for clarity and maintainability. - **Fallback Handling:** If scraping fails (e.g., due to CAPTCHA failure), the script logs an error for that domain and continues. --- ## ‚úÖ Output The final output will look like this: ```json [ { "domain": "notion.so", "domain_rating": 91, "backlinks": 19000000, "linking_websites": 107000, "backlinks_dofollow_percentage": 95, "linking_websites_dofollow_percentage": 82 } ] ``` --- </code></pre>
